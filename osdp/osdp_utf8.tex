\documentclass[pdftex,12pt,a4paper]{article}

\input{/home/boris/Dropbox/Public/tex_general/title_bor_utf8}

%\usepackage{showkeys} % показывать метки

%\input{/home/boris/Dropbox/Public/tex_general/prob_and_sol_utf8}

\title{One shot deviation principle}
\author{Boris Demeshev, boris.demeshev@gmail.com}
\date{\today}

\begin{document}
\parindent=0 pt % Отступ равен 0

Принцип одноразового отклонения в повторяемых играх

One-shot deviation by player  $i$  at history  $k^{t} $

{\it Одноразовым отклонением } $i$ {\it -го игрока от (чистой) стратегии } $s_{i} $ {\it  при истории } $k^{t} $ {\it  }будем называть любую (чистую) стратегию  $r_{i} \in S_{i} $ , такую что  $r_{i} \left(k^{t} \right)\ne s_{i} \left(k^{t} \right)$ , но для любой другой истории  $k^{\tau } $ ,  $r_{i} \left(k^{\tau } \right)=s_{i} \left(k^{\tau } \right)$ .

Более литературно:

Одноразовое отклонение от стратегии  $s_{i} $  - это стратегия  $r_{i} $ , отличающаяся от  $s_{i} $  только в одном узле (или в одной партии для повторяемых игр).

Принцип применим для:

- конечных игр в экстенсивной форме с совершенной информацией

- конечно повторяемых игр

- бесконечно повторяемых игр

и некоторых других

{\it Принцип одноразового отклонения}{\it (}{\it one}{\it -}{\it shot}{\it  }{\it deviation}{\it  }{\it principle}{\it , }{\it OSDP}{\it )}

Профиль чистых стратегий  $s=\left(s_{i} ,s_{-i} \right)$  является равновесием по Нэшу, совершенным в подыграх, тогда и только тогда, когда для любого игрока  $i$ , для любой истории  $k^{t} $  и любого одноразового отклонения  $r_{i} $  от стратегии  $s_{i} $  при истории  $k^{t} $ ,  $u_{i} \left(s_{i} ,s_{-i} |k^{t} \right)\ge u_{i} \left(r_{i} ,s_{-i} |k^{t} \right)$

Более литературно:

Профиль чистых стратегий  $s=\left(s_{i} ,s_{-i} \right)$  является равновесием по Нэшу, совершенным в подыграх, тогда и только тогда, когда ни один игрок не может увеличить свой выигрыш ни в одной подыгре, отклонившись от  $s_{i} $  лишь единожды.

Комментарий:

Чтобы убедиться в том, что некий профиль стратегий является совершенным в подыграх достаточно следующей процедуры:

Взяли некий узел. Убедились в том, что ни одно отклонение в этом узле не приводит к увеличению выигрыша игрока, делающего ход в этом узле, в подыгре, начинающейся с этого узла. Аналогичным образом перебрали остальные узлы.



Доказательство для случая конечной игры в экстенсивной форме с совершенной информацией

Необходимость очевидна.

Докажем достаточность.

Пусть  $s=\left(s_{i} ,s_{-i} \right)$  - профиль, в котором ни у одного из игроков не существует выгодного одноразового отклонения. Предположим, что профиль не является равновесием по Нэшу, совершенным в подыграх. Тогда найдется подыгра  $B$  и стратегия  $r_{i} \ne s_{i} $ , такая что в подыгре  $B$   $i$ -ый игрок предпочитает стратегию  $r_{i} $ ,  $u_{i} \left(r_{i} ,s_{-i} |B\right)>u_{i} \left(s_{i} ,s_{-i} |B\right)$ .

Пусть подыгра  $B$  начинается с истории  $h^{m} $ , т.е.  $M=G\left(h^{m} \right)$ .

Заметим, что  $r_{i} $  и  $s_{i} $  отличаются лишь в конечном числе узлов (в бесконечно повторяемой игре это могло бы быть не так). Идея доказательства состоит в том, что отличия в  $r_{i} $  можно убирать по одному, начиная с самого последнего. При этом ни в одной подыгре платеж от измененной  $r_{i} $  уменьшаться не будет, а в конце концов измененная  $r_{i} $  совпадет с  $s_{i} $ .

Для начала рассмотрим подыгру  $M$ , начинающуюся с узла, где было самое последнее отличие (в произвольной игре с несовершенной информацией это могло бы быть невозможно). В подыгре  $M$  между  $r_{i} $  и  $s_{i} $  есть всего одно отличие, а одиночные отклонения от  $s_{i} $  не могут увеличить платеж игрока в силу принципа одноразового отклонения. Следовательно, убрав в  $r_{i} $  последнее отличие, мы не уменьшим платеж в подыгре  $M$ . Обозначим измененную  $r_{i} $  буквой  $\tilde{r}_{i} $ .

Что произойдет при этом с платежами в других подыграх? Для любой другой подыгры  $M'$ , отличной от  $M$ , выполнено одно из трех соотношений:  $M'\subset M$  (подыгра  $M'$  начинается внутри подыгры  $M$ ),  $M\subset M'$  (подыгра  $M$  начинается внутри подыгры  $M'$ ),  $M'\cap M=\emptyset $  (подыгры  $M'$  и  $M$  не пересекаются).

Случай  $M'\subset M$ . В  $M'$  стратегия  $\tilde{r}_{i} $  никак не отличается от исходной  $r_{i} $ , т.к. внесенное нами в  $r_{i} $  изменение находится до начала подыгры  $M'$ .

Случай  $M'\cap M=\emptyset $ . В  $M'$  стратегия  $\tilde{r}_{i} $  никак не отличается от исходной  $r_{i} $ , т.к. внесенное нами в  $r_{i} $  изменение находится вне подыгры  $M'$ .

Случай  $M\subset M'$ . В этом случае есть две возможности. Начав подыгру  $M'$  и используя стратегию  $r_{i} $  можно либо попасть в подыгру  $M$ , либо не попасть. Если при использовании  $r_{i} $  игрок попадал в подыгру  $M$ , то при использовании  $\tilde{r}_{i} $  игрок также попадет в  $M$  (изменение находится в самой  $M$ ). При этом платеж в подыгре  $M'$  совпадает с платежом в подыгре  $M$ , который при переходе от  $r_{i} $  к  $\tilde{r}_{i} $  не уменьшился. Если же при использовании  $r_{i} $  игрок не попадал в подыгру  $M$ , то при использовании  $\tilde{r}_{i} $  игрок также не попадет в  $M$ , и, следовательно, платеж в подыгре  $M'$  не изменится.



Таким образом, мы получили  $\tilde{r}_{i} $ , которая не хуже  $r_{i} $  ни в одной подыгре, однако имеет на одно отличие от  $s_{i} $  меньше. Аналогичным способом по одному убираем отличия между  $r_{i} $  и  $s_{i} $ . Изменяемая  $\tilde{r}_{i} $  постепенно превращается в  $s_{i} $ . Рано или поздно изменяемая  $\tilde{r}_{i} $  полностью совпадет с  $s_{i} $  в подыгре  $B$ . Получается противоречие, так как с одной стороны  $r_{i} $  была строго лучше  $s_{i} $  в подыгре  $B$ , а с другой стороны  $\tilde{r}_{i} $  является последовательно улучшенной  $r_{i} $ , а платеж от  $s_{i} $  совпадает с платежом от  $\tilde{r}_{i} $ .



Доказательство для случая бесконечно повторяемых игр

Доказательство полностью аналогично предыдущему, с единственным отличием. Пусть снова  $r_{i} $  более выгодна чем  $s_{i} $  в некой подыгре  $B$ . Проблема заключается в том, что  $r_{i} $  может отличаться от  $s_{i} $  в бесконечном количестве партий. Требуется так изменить отклонение  $r_{i} $ , чтобы оно отличалось от  $s_{i} $  лишь в конечном числе узлов.

Это всегда возможно в силу того, что бесконечно повторяемые игры обладают свойством {\it трансверсальности}.

{\it Условие трансверсальности (условие непрерывности на бесконечности).}

{\it (}{\it transversality}{\it  }{\it condition}{\it , }{\it continuity}{\it  }{\it at}{\it  }{\it infinity}{\it )}

Если два профиля стратегий не отличаются в течение первых  $t$  партий, то различие в платежах от этих профилей должно стремиться к нулю при  $t\to \infty $ .

$$\mathop{\lim }\limits_{t\to \infty } \mathop{\sup }\limits_{\sigma \left(h^{\tau } \right)=\tilde{\sigma }\left(h^{\tau } \right),\forall \tau <t} \left|u_{i} \left(\sigma \right)-u_{i} \left(\tilde{\sigma }\right)\right|=0$$

Бесконечно повторяемые игры удовлетворяют этому условию в силу того, что существует разница  $d=\left|u_{\max } -u_{\min } \right|$  между максимальным и минимальным платежами  в базовой игре, и  $\mathop{\lim }\limits_{t\to \infty } \delta ^{t} \frac{d}{1-\delta } =0$  Заметим, что игры, оканчивающиеся за конечное число ходов, очевидно, удовлетворяют этому условию. Если  $t$  превысило максимальное количество ходов, то платежи от двух профилей в точности совпадают.

В силу условия трансверсальности все ходы в  $r_{i} $  начиная с некоего  $N$  можно заменить на ходы из  $s_{i} $ . При этом  $N$  можно выбрать так, что платеж от измененной  $r_{i} $  будет сколь угодно мало отличаться от платежа исходной  $r_{i} $  в подыгре  $B$ . Стратегия  $r_{i} $  в подыгре  $B$  была строго лучше  $s_{i} $ , а значит и измененная  $r_{i} $  будет строго предпочитаться  $s_{i} $  в подыгре  $B$ . Однако измененная  $r_{i} $  имеет лишь конечное число отличий от  $s_{i} $ .

В остальном доказательство аналогично случаю игры, оканчивающейся за конечное число ходов.

Примеры использования

Пример 1.

Рассмотрим бесконечно повторяющуюся игру с базовой игрой  $\begin{array}{|c|cc|}  \hline {} & {c} & {d} \\  \hline {c} & {\left(2;2\right)} & {\left(0;3\right)} \\ {d} & {\left(3;0\right)} & {\left(1;1\right)} \\  \hline  \end{array}$ .

При каких значениях дисконт-фактора пара стратегий (стратегия переключения; в первой партии сыграть «с», в последующих повторять действия противника в предыдущей) будет равновесием по Нэшу, совершенным в подыграх?

Напомним, что с{\bf тратегия переключения} (grim trigger) предписывает играть ход  $c$  в первой партии и далее до тех пор, пока оба игрока играют ход  $c$ :

Решение

Рассмотрим подыгры, начинающиеся с истории  $\left\{\left(c,c\right),\left(c,c\right),...,\left(c,c\right)\right\}$

Пусть в начале такой подыгре первый игрок делает одиночное отклонение.

Тогда в подыгре события развиваются так:  $...,\underbrace{\left(d,c\right)}_{deviation\; period},\left(d,d\right),\left(d,d\right),...$

После периода отклонения первый игрок играет ход  $d$ , т.к. это предписывается стратегией переключения, к которой он вернулся.

Платеж первого игрока при таком отклонении составит:  $3+1\cdot \frac{\delta }{1-\delta } $

Необходимо неравенство  $3+1\cdot \frac{\delta }{1-\delta } \le 2\cdot \frac{1}{1-\delta } $ .

Пусть в начале подыгры второй игрок делает одиночное отклонение:

Тогда события развиваются так:  $...,\underbrace{\left(c,d\right)}_{deviation\; period},\left(d,c\right),\left(d,d\right),\left(d,d\right)...$

После периода отклонения первый игрок играет ход  $d$ , т.к. это предписывается стратегией переключения, а второй игрок копирует действия первого в предыдущей партии (т.к. он вернулся к этой стратегии).

Платеж второго игрока при таком отклонении составит:  $3+0\cdot \delta +1\cdot \frac{\delta ^{2} }{1-\delta } $

Необходимо неравенство  $3+0\cdot \delta +1\cdot \frac{\delta ^{2} }{1-\delta } \le 2\cdot \frac{1}{1-\delta } $

Рассмотрим подыгры, начинающиеся с истории отличной от  $\left\{\left(c,c\right),\left(c,c\right),...,\left(c,c\right)\right\}$

Есть четыре варианта окончания таких подыгр (нам интересно только то, чем оканчивается подыгра в силу стратегии второго игрока). Они могут оканчиваться на  $\left(c,c\right)$ ,  $\left(c,d\right)$ ,  $\left(d,c\right)$  или  $\left(d,d\right)$ .

Рассмотрим истории типа  $\left\{\left(?,?\right),\left(?,?\right),...,\left(?,?\right),\left(c,d\right)\right\}$

Если игроки не отклоняются от своих стратегий в подыгре, следующей за такой историей, то события развиваются так:  $\left(d,c\right),\left(d,d\right),\left(d,d\right),\left(d,d\right),...$ . Без вычислений видно, что второму игроку выгодно использовать одиночное отклонение в первой партии подыгры, чтобы события развивались  $\left(d,d\right),\left(d,d\right),\left(d,d\right),\left(d,d\right),...$

Рассмотрение остальных трех вариантов не имеет смысла, т.к. уже ясно, что предложенный профиль не является равновесием по Нэшу, совершенным в подыграх, ни при каких значениях дисконт-фактора.



Пример 2.

Рассмотрим бесконечно повторяющуюся игру с базовой игрой  $\begin{array}{|c|cc|}  \hline {} & {c} & {d} \\  \hline {c} & {\left(2;2\right)} & {\left(0;3\right)} \\ {d} & {\left(3;0\right)} & {\left(1;1\right)} \\  \hline  \end{array}$ .

При каких значениях дисконт-фактора пара стратегий двухходового возмездия будет равновесием по Нэшу, совершенным в подыграх?

Стратегия двухходового возмездия: в начале сыграть ход «с» и играть «с» до тех пор, пока играется  $\left(c,c\right)$ ; если было сыграно не  $\left(c,c\right)$ , то в течение двух последующих партий играть ход «d», затем действовать, как будто игра начиналась заново.

Решение

Игрок может использовать одноразовое отклонение либо находясь в фазе возмездия, либо находясь в стадии кооперации.

Рассмотрим одноразовое отклонение, совершаемое в фазе кооперации:

Пусть отклоняется первый игрок. События развиваются так:

$$...,\underbrace{\left(d,c\right)}_{deviation\; period},\left(d,d\right),\left(d,d\right),\left(c,c\right),\left(c,c\right),...$$

Во второй и третьей партиях от момента отклонения первый игрок уже вернулся к стратегии двухходового возмездия и наказывает сам себя согласно стратегии.

Платеж первого игрока будет равен  $3+1\cdot \delta +1\cdot \delta ^{2} +2\cdot \frac{\delta ^{3} }{1-\delta } $ .

Необходимо неравенство  $3+1\cdot \delta +1\cdot \delta ^{2} +2\cdot \frac{\delta ^{3} }{1-\delta } \le 2\cdot \frac{1}{1-\delta } $

Аналогичное неравенство возникнет, если одноразовое отклонение будет использовать второй игрок.

Рассмотрим одноразовое отклонение, совершаемое в фазе возмездия.

События развиваются либо:  $...,\underbrace{\left(c,d\right)}_{deviation\; period},\left(d,d\right),\left(c,c\right),\left(c,c\right),...$  (если это начало фазы возмездия).

Либо:  $...,\underbrace{\left(c,d\right)}_{deviation\; period},\left(c,c\right),\left(c,c\right),...$  (если отклонение происходит в конце фазы возмездия).

В любом случае, очевидно, что подобное отклонение не выгодно.

Решаем неравенство  $3+1\cdot \delta +1\cdot \delta ^{2} +2\cdot \frac{\delta ^{3} }{1-\delta } \le 2\cdot \frac{1}{1-\delta } $ . Получаем  $\delta ^{3} -2\delta +1\le 0$  и в результате  $\delta \in \left[\frac{\sqrt{5} -1}{2} ;1\right)$ .

{\bf }Приложение. Названия некоторых стратегий в повторяющейся дилемме заключенного

Обозначения:

 $a^{t} $  - исход базовой игры с номером  $t$ ;

 $a_{i}^{t} $  - ход сделанный  $i$ -ым игроком в базовой игре с номером  $t$ .

 $s_{i} $  - стратегия  $i$ -го игрока;

 $h^{t} $  - предыстория игры к моменту времени  $t$ :  $h^{t} =\left\{a^{1} ,a^{2} ,...a^{t-1} \right\}$ ;

 $s_{i} \left(h^{t} \right)$  - ход, предписываемый стратегией  $s_{i} $  после истории  $h^{t} $  (в момент  $t$ );

 $G\left(h^{t} \right)$  - подыгра, начинающаяся с истории  $h^{t} $

\textbf{ Стратегия "Всегда кооперироваться"} (always cooperate)

Предписывает всегда играть ход  $c$ :  $s_{i} \left(h^{t}
\right)=c,\quad \forall t$ \textbf{Наивная стратегия переключения}
(na?ve grim trigger)

Предписывает играть ход  $c$  в первой партии и далее до тех пор, пока противник играет ход  $c$ :  $s_{i} \left(h^{t} \right)=\left\{\begin{array}{l} {c,\quad t=1} \\ {c,\quad t>1,\quad \forall \tau <t\Rightarrow a_{j}^{\tau } =c} \\ {d,\quad otherwise} \end{array}\right. $

{\bf Стратегия переключения} (grim trigger)

Предписывает играть ход  $c$  в первой партии и далее до тех пор, пока оба игрока играют ход  $c$ :  $s_{i} \left(h^{t} \right)=\left\{\begin{array}{l} {c,\quad t=1} \\ {c,\quad t>1,\quad \forall \tau <t\Rightarrow a^{\tau } =\left(c;c\right)} \\ {d,\quad otherwise} \end{array}\right. $

{\bf Стратегия Зуб за зуб} (Tit for Tat)

Предписывает играть ход  $c$  в первой партии и далее повторять ход противника в предыдущей партии:  $s_{i} \left(h^{t} \right)=\left\{\begin{array}{l} {c,\quad t=1} \\ {a_{j}^{t-1} ,\quad t>1} \end{array}\right. $

{\bf Стратегия Кнута и Пряника} (Win-Stay, Lose-Shift; Pavlov strategy)

Предписывает играть ход  $c$  в первой партии и далее играть ход  $c$ , если в предыдущей партии действия игроков совпали:  $s_{i} \left(h^{t} \right)=\left\{\begin{array}{l} {c,\quad t=1} \\ {c,\quad t>1,\quad a^{t-1} \in \left\{\left(c;c\right),\left(d;d\right)\right\}} \\ {d,\quad otherwise} \end{array}\right. $

{\it Тигр: }{\it Э}{\it та хитрая стратегия была }{\it внедрена}{\it  известными специалистами по теории игр Кнутом Б.Б. и Пряником В.Л.}

{\bf Стратегия ограниченного возмездия} (limited retaliation)

Предписывает играть ход  $c$ , пока все игроки кооперируются. Если произошло нарушение, то в течение  $k$  ходов играть  $d$ , затем вернуться в исходное состояние. Состоит из трех фаз:

Фаза 1: сыграть ход  $c$  и переключиться в фазу 2;

Фаза 2: играть ход  $c$  до тех пор, пока все игроки играют ход  $c$ , в противном случае переключиться в фазу 3, положив  $\tau :=0$ ;

Фаза 3: пока  $\tau \le k$ , положить  $\tau :=\tau +1$  и играть ход  $d$ , иначе переключиться в фазу 1.


\end{document}